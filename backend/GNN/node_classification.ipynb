{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration Network Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joel/repos/cscollab/backend\n"
     ]
    }
   ],
   "source": [
    "%cd /home/joel/repos/cscollab/backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import kuzudb.query_kuzu as query\n",
    "import collections\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Running on', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "\n",
    "First we create some mappings for the kuzudb data:\n",
    "A mapping from the subarea id to the area id and a mapping of authors to their affiliated institution.\n",
    "Further each reasearch area and subarea is onehot encoded and saved in a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'systems': tensor([1., 0., 0., 0.]), 'ai': tensor([0., 1., 0., 0.]), 'theory': tensor([0., 0., 1., 0.]), 'interdiscip': tensor([0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" mapping of sub areas to areas\"\"\"\n",
    "area_mapping = query.get_area_mapping()\n",
    "subarea_mapping = dict(zip(area_mapping[\"sub-area-id\"],area_mapping[\"area-id\"]))\n",
    "\n",
    "\"\"\"one hot encoding\"\"\"\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "area_ids = list(area_mapping[\"area-id\"].unique())\n",
    "n_area = len(area_ids)\n",
    "onehot_encoded_areas = onehot_encoder.fit_transform(np.arange(n_area).reshape(n_area,1))\n",
    "tensor_list_ohe_areas = list(map(lambda x: torch.tensor(x, dtype=torch.float), onehot_encoded_areas))\n",
    "area_ohe_mapping = dict(zip(area_ids,tensor_list_ohe_areas))\n",
    "print(area_ohe_mapping)\n",
    "\n",
    "sub_area_ids = area_mapping[\"sub-area-id\"].unique()\n",
    "n_sub_area = len(sub_area_ids)\n",
    "onehot_encoded_sub_areas = onehot_encoder.fit_transform(np.arange(n_sub_area).reshape(n_sub_area,1))\n",
    "# tensor_list_ohe_sub_areas = list(map(lambda x: torch.tensor(x, dtype=torch.float), onehot_encoded_sub_areas))\n",
    "sub_area_ohe_mapping = dict(zip(sub_area_ids,onehot_encoded_sub_areas))\n",
    "\n",
    "\"\"\"mapping of author to institution\"\"\"\n",
    "csauthors_all = query.get_csauthors()\n",
    "author_inst_map = dict(zip(csauthors_all[\"pid\"],csauthors_all[\"institution\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a collaboration network we want to get for each node (author or institution) what the frequency of publications in the different areas and sub areas are and in which sub/area the most publications. For this we define a function to count the frequency and a function to get the collaboration network based on a config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" count the frequency of sub/areas for a node\"\"\"\n",
    "def area_frequency_counter(collab, node):\n",
    "    collab_node = collab[(collab[\"a\"]==node) | (collab[\"b\"]==node)]\n",
    "    area_counter = dict(collections.Counter(collab_node[\"rec_area\"]))\n",
    "    top_area = max(area_counter, key=area_counter.get)\n",
    "    sub_area_counter = dict(collections.Counter(collab_node[\"rec_sub_area\"]))\n",
    "    top_sub_area = max(sub_area_counter, key=sub_area_counter.get)\n",
    "    freq= {\"area_freq\":area_counter,\n",
    "            \"top_area\":top_area,\n",
    "            \"sub_area_freq\":sub_area_counter,\n",
    "            \"top_sub_area\":top_sub_area}\n",
    "    return freq\n",
    "\n",
    "\n",
    "def get_collab_data(config):\n",
    "    \"\"\"get collaboration\"\"\"\n",
    "    collab = query.get_collaboration(config)  \n",
    "    collab[\"rec_area\"]=list(map(lambda x: subarea_mapping[x], collab[\"rec_sub_area\"]))  \n",
    "        \n",
    "    if config.get(\"institution\",False):\n",
    "        collab[\"a\"] = list(map(lambda x: author_inst_map[x], collab[\"a\"].values))\n",
    "        collab[\"b\"] = list(map(lambda x: author_inst_map[x], collab[\"b\"].values))\n",
    "\n",
    "\n",
    "    \"\"\"map each institution or author to an int based on the positional index\"\"\"\n",
    "    nodes = list(set(collab[\"a\"]).union(set(collab[\"b\"])))\n",
    "    node_idx = list(range(len(nodes)))\n",
    "    node_idx_mapping = dict(zip(nodes, node_idx))\n",
    "\n",
    "    frequency_map = dict(zip(node_idx, list(map(lambda n: area_frequency_counter(collab, n), nodes))))\n",
    "\n",
    "    collab_weighted = query.get_weighted_collab(config)\n",
    "    collab_weighted[\"a\"] = list(map(lambda n: node_idx_mapping[n],collab_weighted[\"a\"]))\n",
    "    collab_weighted[\"b\"] = list(map(lambda n: node_idx_mapping[n],collab_weighted[\"b\"]))\n",
    "    \n",
    "    adjacency_list = list(map(list,zip(collab_weighted[\"a\"], collab_weighted[\"b\"])))\n",
    "    weights = collab_weighted[\"weight\"].values\n",
    "\n",
    "    data = {\"nodes\": node_idx,\n",
    "            \"edges\":adjacency_list,\n",
    "            \"weights\":weights,\n",
    "            \"freq\": frequency_map}\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define a config a check the collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of first 10 nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Number of first 10 edges: [[59, 59], [78, 59], [77, 77], [1, 1], [13, 13], [5, 5], [66, 66], [38, 5], [59, 5], [12, 32]]\n",
      "Number of first 10 weights: [88 81 76 74 73 69 53 48 42 38]\n",
      "Frequency mapping of the first node: {'area_freq': {'interdiscip': 1, 'ai': 3, 'systems': 1}, 'top_area': 'ai', 'sub_area_freq': {'robotics': 1, 'ml': 3, 'networks': 1}, 'top_sub_area': 'ml'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"define config as the collabortaion between institutions among Austria, Germany and Switzerland later than 2015\"\"\"\n",
    "config = { \"from_year\": 2015,\n",
    "            \"region_id\":\"dach\",\n",
    "            \"strict_boundary\":True,\n",
    "            \"institution\":True}\n",
    "\n",
    "collab_data = get_collab_data(config)\n",
    "print()\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of first 10 nodes: {collab_data[\"nodes\"][:10]}')\n",
    "print(f'Number of first 10 edges: {collab_data[\"edges\"][:10]}')\n",
    "print(f'Number of first 10 weights: {collab_data[\"weights\"][:10]}')\n",
    "print(f'Frequency mapping of the first node: {collab_data[\"freq\"][0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the torch data object:\n",
    "\n",
    "* y is the onehot encoding of the research area with the most publications\n",
    "* x is the percentage of published subareas calculated using the ohe of the subareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"get target label as the area with the most records published\"\"\"\n",
    "def get_y(nodes, freq):\n",
    "    top_areas = list(map(lambda x: freq[x][\"top_area\"], nodes))\n",
    "    \n",
    "    \"\"\"get target label as torch tensor\"\"\"\n",
    "    y = torch.tensor(list(map(lambda x: list(area_ohe_mapping[x]),top_areas)),dtype=torch.float)\n",
    "    # y = torch.tensor(list(map(lambda x: area_ids.index(x),top_areas)),dtype=torch.float)\n",
    "    return y\n",
    "\n",
    "def sub_area_frequency(freq,n):\n",
    "    sfreq = freq[n][\"sub_area_freq\"]\n",
    "    \"\"\"sum up one hot endocings of the subareas by their frequency\"\"\"\n",
    "    freq_array = functools.reduce(lambda x, key: x + sfreq[key] * sub_area_ohe_mapping[key], sfreq, np.zeros(n_sub_area))\n",
    "    \"\"\"get frequency as percentage such that it sums up to 1\"\"\"\n",
    "    freq_array_p = freq_array/sum(sfreq.values())\n",
    "    return freq_array_p \n",
    "\n",
    "\"\"\"the percentage of published subareas\"\"\"\n",
    "def get_x(nodes,freq):\n",
    "    x =  torch.tensor(np.array(list(map(lambda node: sub_area_frequency(freq,node) ,nodes))), dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "def gen_torch_data(nodes,edges, freq, use_x=True ,weights=None):\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    y = get_y(nodes,freq)\n",
    "    \n",
    "    ohe = torch.eye(len(nodes))\n",
    "    if use_x:\n",
    "        x = torch.cat((get_x(nodes, freq), ohe), dim=1)\n",
    "    else:\n",
    "        x = ohe\n",
    "    \n",
    "    if weights is not None:\n",
    "        weights = torch.tensor(weights,dtype=torch.long)\n",
    "        \n",
    "    \"\"\"create torch data object without weights\"\"\"\n",
    "    data = torch_geometric.data.Data(x=x, y=y, edge_index=edge_index, num_nodes=len(nodes))\n",
    "    data = T.ToUndirected()(data) # the collaboration network is undirected\n",
    "    data = T.AddSelfLoops()(data) # by adding self-loops, we ensure that aggregated messages from neighbors \n",
    "    data = T.NormalizeFeatures()(data) # features will sum up to 1\n",
    "    \"\"\" define train test split\"\"\"\n",
    "    transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.3, num_test=0)\n",
    "    transform(data)\n",
    "    return data\n",
    "\n",
    "def collab_to_torch(config, weighted=False, use_x =True):\n",
    "    collab_data = get_collab_data(config)\n",
    "    nodes = collab_data[\"nodes\"]\n",
    "    edges = collab_data[\"edges\"]\n",
    "    weights = collab_data[\"weights\"] if weighted else None\n",
    "    freq = collab_data[\"freq\"]\n",
    "    data = gen_torch_data(nodes, edges, freq, use_x=use_x, weights=weights)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[81, 104], edge_index=[2, 1129], y=[81, 4], num_nodes=81, train_mask=[81], val_mask=[81], test_mask=[81])\n",
      "Number of nodes: 81\n",
      "Number of edges: 1129\n",
      "Number of features: 104\n",
      "Number of training nodes: 57\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Features of first node: tensor([0.0000, 0.3000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "Sub area frequency of the first node: {'robotics': 1, 'ml': 3, 'networks': 1}\n",
      "Sum of ohe of the subfrquencies of the first node: [0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"torch data object\"\"\"\n",
    "data = collab_to_torch(config)\n",
    "print(data)\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {data.num_features}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "\"\"\" take a closer look at features\"\"\"\n",
    "print(f'Features of first node: {data.x[0]}')\n",
    "print(f'Sub area frequency of the first node: {collab_data[\"freq\"][0][\"sub_area_freq\"]}')\n",
    "print(f'Sum of ohe of the subfrquencies of the first node: {sub_area_ohe_mapping[\"robotics\"] + 3*sub_area_ohe_mapping[\"ml\"] + sub_area_ohe_mapping[\"networks\"]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(torch_geometric.nn.MessagePassing):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__(aggr='add')\n",
    "\n",
    "        # this linear function is used to transform node features \n",
    "        # into messages that are then \"sent\" to neighbors\n",
    "        self.linear = torch.nn.Linear(in_ch, out_ch)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        This function uses the edges captured in edge_index, performs \n",
    "        the graph convolution function according to (Kipf, Welling 2017)\n",
    "        and propagates the transformed features along the edges of the graph\n",
    "        \"\"\"\n",
    "\n",
    "        # we linearly transform the features of *all* nodes stored in x\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # extract source and target nodes of all edges\n",
    "        source, target = edge_index\n",
    "        \n",
    "        # compute the (in-)degrees $d_i$ of source nodes\n",
    "        deg = torch_geometric.utils.degree(target, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        # with this, the normalization to be applied in the propagation step can be expressed as\n",
    "        # this corresponds to D^{-0.5} A * D^{-0.5} in (Kipf, Welling 2017)\n",
    "        norm = deg_inv_sqrt[source] * deg_inv_sqrt[target]\n",
    "        \n",
    "        # the propagate function propagates messages along the edges of the graph\n",
    "        # this function internally calls the functions: message(), aggregate() and update()\n",
    "        # the normalization is applied in the message() function\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        # x_j is a so-called **lifted** tensor which contains the source node features of each edge, \n",
    "        # i.e. it has a shape (m, out_ch) where m is the number of edges\n",
    "\n",
    "        # a call to view(-1, 1) returns a reshaped tensor, where the second dimension \n",
    "        # is one and the first dimension is inferred automatically\n",
    "        return norm.view(-1,1) * x_j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, data: torch_geometric.data.Data, out_ch, hidden_dim=16):\n",
    "        super().__init__()\n",
    "\n",
    "        # first convolution layer \n",
    "        self.input_to_hidden = GraphConvolution(data.num_node_features, hidden_dim)\n",
    "\n",
    "        # second convolution layer\n",
    "        self.hidden_to_output =  GraphConvolution(hidden_dim, out_ch)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        # first graph convolution -> map nodes to representations in hidden_dim dimensions\n",
    "        x = self.input_to_hidden(x, edge_index)\n",
    "\n",
    "        # non-linear activation function\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        # second graph convolution -> maps node representations to output classes\n",
    "        x = self.hidden_to_output(x, edge_index)\n",
    "\n",
    "        # output class probabilities\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (input_to_hidden): GraphConvolution()\n",
      "  (hidden_to_output): GraphConvolution()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GCN(data, out_ch=4, hidden_dim=4)\n",
    "\n",
    "epochs = 10000\n",
    "lrn_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lrn_rate)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainging of the model\n",
    "\n",
    "Does not converge to 0 !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.num_nodes)\n",
    "losses = []\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    error = 0\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    for i in indices:\n",
    "\n",
    "        if data.train_mask[i]:\n",
    "\n",
    "            # set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute loss function for training sample and backpropagate\n",
    "            output = model(data.x, data.edge_index)\n",
    "            loss = torch.nn.functional.binary_cross_entropy(output[i], data.y[i])\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            error += loss.detach().numpy()\n",
    "\n",
    "    losses.append(error)\n",
    "\n",
    "# plot evolution of loss function\n",
    "plt.plot(range(epochs), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4790, 0.4799, 0.0467, 0.1288],\n",
      "        [0.4637, 0.4667, 0.0073, 0.0427],\n",
      "        [0.4718, 0.4741, 0.0218, 0.0829],\n",
      "        [0.4630, 0.4649, 0.0052, 0.0348],\n",
      "        [0.4745, 0.4766, 0.0296, 0.0992],\n",
      "        [0.4506, 0.4542, 0.0011, 0.0133],\n",
      "        [0.4625, 0.4650, 0.0056, 0.0364],\n",
      "        [0.4716, 0.4730, 0.0181, 0.0739],\n",
      "        [0.4713, 0.4735, 0.0187, 0.0756],\n",
      "        [0.4690, 0.4710, 0.0125, 0.0592],\n",
      "        [0.4656, 0.4678, 0.0075, 0.0434],\n",
      "        [0.4778, 0.4789, 0.0415, 0.1206],\n",
      "        [0.4701, 0.4720, 0.0154, 0.0671],\n",
      "        [0.4504, 0.4541, 0.0011, 0.0133],\n",
      "        [0.4757, 0.4768, 0.0311, 0.1018],\n",
      "        [0.4606, 0.4639, 0.0048, 0.0334],\n",
      "        [0.4740, 0.4749, 0.0235, 0.0862],\n",
      "        [0.4544, 0.4576, 0.0018, 0.0181],\n",
      "        [0.4596, 0.4629, 0.0041, 0.0303],\n",
      "        [0.4734, 0.4751, 0.0232, 0.0857],\n",
      "        [0.4733, 0.4757, 0.0274, 0.0949],\n",
      "        [0.4679, 0.4705, 0.0129, 0.0605],\n",
      "        [0.4472, 0.4503, 0.0006, 0.0089],\n",
      "        [0.4730, 0.4751, 0.0249, 0.0896],\n",
      "        [0.4764, 0.4771, 0.0320, 0.1034],\n",
      "        [0.4623, 0.4653, 0.0058, 0.0374],\n",
      "        [0.4714, 0.4734, 0.0187, 0.0755],\n",
      "        [0.4757, 0.4771, 0.0328, 0.1053],\n",
      "        [0.4785, 0.4800, 0.0488, 0.1326],\n",
      "        [0.4715, 0.4729, 0.0158, 0.0681],\n",
      "        [0.4668, 0.4690, 0.0099, 0.0514],\n",
      "        [0.4669, 0.4697, 0.0113, 0.0560],\n",
      "        [0.4604, 0.4629, 0.0040, 0.0294],\n",
      "        [0.4693, 0.4717, 0.0150, 0.0662],\n",
      "        [0.4800, 0.4807, 0.0514, 0.1362],\n",
      "        [0.4753, 0.4761, 0.0274, 0.0945],\n",
      "        [0.4710, 0.4729, 0.0171, 0.0714],\n",
      "        [0.4544, 0.4574, 0.0017, 0.0174],\n",
      "        [0.4642, 0.4670, 0.0075, 0.0437],\n",
      "        [0.4601, 0.4635, 0.0046, 0.0323],\n",
      "        [0.4793, 0.4796, 0.0441, 0.1247],\n",
      "        [0.4768, 0.4782, 0.0318, 0.1030],\n",
      "        [0.4702, 0.4727, 0.0171, 0.0718],\n",
      "        [0.4705, 0.4724, 0.0158, 0.0681],\n",
      "        [0.4727, 0.4742, 0.0208, 0.0803],\n",
      "        [0.4730, 0.4744, 0.0212, 0.0811],\n",
      "        [0.4723, 0.4749, 0.0247, 0.0893],\n",
      "        [0.4602, 0.4632, 0.0043, 0.0311],\n",
      "        [0.4691, 0.4715, 0.0145, 0.0650],\n",
      "        [0.4752, 0.4770, 0.0309, 0.1017],\n",
      "        [0.4605, 0.4626, 0.0037, 0.0283],\n",
      "        [0.4646, 0.4676, 0.0084, 0.0467],\n",
      "        [0.4748, 0.4765, 0.0288, 0.0975],\n",
      "        [0.4755, 0.4764, 0.0269, 0.0935],\n",
      "        [0.4687, 0.4714, 0.0141, 0.0639],\n",
      "        [0.4698, 0.4723, 0.0165, 0.0701],\n",
      "        [0.4800, 0.4804, 0.0497, 0.1333],\n",
      "        [0.4564, 0.4596, 0.0025, 0.0220],\n",
      "        [0.4760, 0.4772, 0.0328, 0.1050],\n",
      "        [0.4512, 0.4549, 0.0012, 0.0142],\n",
      "        [0.4735, 0.4749, 0.0229, 0.0851],\n",
      "        [0.4672, 0.4699, 0.0117, 0.0573],\n",
      "        [0.4738, 0.4754, 0.0250, 0.0895],\n",
      "        [0.4536, 0.4571, 0.0017, 0.0177],\n",
      "        [0.4738, 0.4753, 0.0245, 0.0885],\n",
      "        [0.4802, 0.4807, 0.0505, 0.1345],\n",
      "        [0.4615, 0.4647, 0.0054, 0.0358],\n",
      "        [0.4582, 0.4615, 0.0033, 0.0261],\n",
      "        [0.4800, 0.4815, 0.0605, 0.1500],\n",
      "        [0.4539, 0.4567, 0.0016, 0.0166],\n",
      "        [0.4686, 0.4708, 0.0127, 0.0598],\n",
      "        [0.4622, 0.4654, 0.0061, 0.0385],\n",
      "        [0.4694, 0.4712, 0.0135, 0.0622],\n",
      "        [0.4755, 0.4774, 0.0338, 0.1073],\n",
      "        [0.4752, 0.4768, 0.0289, 0.0978],\n",
      "        [0.4670, 0.4689, 0.0091, 0.0488],\n",
      "        [0.4577, 0.4603, 0.0027, 0.0233],\n",
      "        [0.4564, 0.4596, 0.0025, 0.0220],\n",
      "        [0.4706, 0.4731, 0.0186, 0.0755],\n",
      "        [0.4555, 0.4587, 0.0021, 0.0199],\n",
      "        [0.4730, 0.4756, 0.0272, 0.0945]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model.forward(data.x, data.edge_index)\n",
    "prediction = output\n",
    "\n",
    "true_prediction = [data.y[x].argmax().item()==prediction[x].argmax().item() for x in range(data.num_nodes)]\n",
    "accuracy=sum(true_prediction)/len(true_prediction)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57b8c90b89213abe2a18d2e7f3355117aeb6585e159ae114dd1387e67a9ebd95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
